
//          Copyright Gavin Band 2008 - 2012.
// Distributed under the Boost Software License, Version 1.0.
//    (See accompanying file LICENSE_1_0.txt or copy at
//          http://www.boost.org/LICENSE_1_0.txt)


#include <vector>
#include <unordered_map>
#include <ctime>
#include <boost/function.hpp>
#include <boost/format.hpp>
#include <boost/filesystem.hpp>
#include <boost/timer/timer.hpp>
#include <boost/functional/hash.hpp>
#include <boost/random/mersenne_twister.hpp>
#include <boost/random/discrete_distribution.hpp>
#include <boost/bind.hpp>

#include "config/qctool_version_autogenerated.hpp"

#include "metro/constants.hpp"
#include "metro/ShotgunStochasticSearch.hpp"
#include "metro/regression/Design.hpp"
#include "metro/regression/Logistic.hpp"
#include "metro/IndependentParameterDistribution.hpp"
#include "metro/distributions/LogF.hpp"
#include "metro/distributions/Flat.hpp"
#include "metro/regression/LogUnnormalisedPosterior.hpp"
#include "metro/intersect_ranges.hpp"
#include "metro/regression/fit_model.hpp"
#include "metro/SampleRange.hpp"
#include "metro/log_sum_exp.hpp"

#include "appcontext/CmdLineOptionProcessor.hpp"
#include "appcontext/ApplicationContext.hpp"

#include "genfile/MissingValue.hpp"
#include "genfile/bgen/View.hpp"
#include "genfile/bgen/Query.hpp"
#include "genfile/SNPDataSource.hpp"
#include "genfile/db/Error.hpp"
#include "genfile/ToGP.hpp"
#include "genfile/CrossCohortCovariateValueMapping.hpp"
#include "genfile/CommonSNPFilter.hpp"
#include "genfile/VariantIdentifyingDataFilteringSNPDataSource.hpp"

#include "qcdb/FlatFileMultiVariantOutputter.hpp"

namespace bfs = boost::filesystem ;

// #define DEBUG 1
// #define DEBUG_DOSAGESTORE 1

namespace globals {
	std::string const program_name = "multifinemap" ;
	std::string const program_version = qctool_version ;
	std::string const program_revision =  std::string( qctool_revision ).substr( 0, 7 ) ;
}

namespace {
	std::string print_state( std::size_t N, std::vector< std::size_t > const& states ) {
		std::string result = "[";
		std::size_t begin = 0 ;
		for( std::size_t i = 0; i <= states.size(); ++i ) {
			std::size_t end = (i==states.size()) ? N : states[i] ;
			for( std::size_t j = begin; j < end; ++j ) {
				result.push_back( '0' ) ;
			}
			if( end != N ) {
				result.push_back( '1' ) ;
			}
			begin = end+1 ;
		}
		result += ']' ;
		return result ;
	}
}

struct MFMOptions: public appcontext::CmdLineOptionProcessor
{
public:
	std::string get_program_name() const { return globals::program_name ; }

	void declare_options( appcontext::OptionProcessor& options ) {
		// Meta-options
		options.set_help_option( "-help" ) ;
		options.set_spec_option( "-spec" ) ;

		// File options
		options.declare_group( "Input file options" ) ;
	    options[ "-g" ]
	        .set_description( 	"Path to BGEN file giving genotypes." )
			.set_takes_values( 1 )
			.set_minimum_multiplicity( 1 )
			.set_maximum_multiplicity( 1 ) ;
	    options[ "-filetype" ]
			.set_description(
				"Specify the filetype of the genotype files specified by -g. "
				"By default, qctool will guess the file type.  Use this option to override that guess. "
				"Possible types are: \"" + genfile::string_utils::join( genfile::SNPDataSource::get_file_types(), "\",\"" ) + "\"." )
			.set_takes_single_value()
			.set_default_value( "guess" ) ;

	    options[ "-assume-chromosome" ]
	        .set_description( "Chromosome to assume if not in genetic data." )
			.set_takes_single_value() ;
	    options[ "-s" ]
	        .set_description( "Path of sample file to input.  If specified, this option must occur as often as the -g option"
							" to specify one sample file per cohort." )
			.set_takes_values( 1 )
			.set_minimum_multiplicity( 1 )
			.set_maximum_multiplicity( 1000 ) ;
		options[ "-outcome" ]
			.set_description( "Name of column containing outcome.  Currently must be a binary outcome." )
			.set_takes_single_value()
			.set_is_required() ;
		
		options.declare_group( "Input filtering options" ) ;
		options[ "-incl-range" ]
			.set_description( "Specify a range of SNPs (or comma-separated list of ranges of SNPs) to operate on. "
				"Each range should be in the format CC:xxxx-yyyy where CC is the chromosome and xxxx and yyyy are the "
				"start and end coordinates, or just xxxx-yyyy which matches that range from all chromosomes. "
				"You can also omit either of xxxx or yyyy to get all SNPs from the start or to the end of a chromosome." )
			.set_takes_values_until_next_option() ;
		options[ "-excl-range" ]
			.set_description( "Specify a range of SNPs (or comma-separated list of ranges of SNPs) to exclude from operation. "
				"Each range should be in the format CC:xxxx-yyyy where CC is the chromosome and xxxx and yyyy are the "
				"start and end coordinates, or just xxxx-yyyy which matches that range from all chromosomes. "
				"You can also omit either of xxxx or yyyy to get all SNPs from the start or to the end of a chromosome." )
			.set_takes_values_until_next_option() ;
		options[ "-incl-ranges" ]
			.set_description( "Like -incl-range, but read the ranges from the specified file."
				"The file must contain a whitespace-separated list of genomic ranges to include in the analysis." )
			.set_takes_values_until_next_option() ;
		options[ "-excl-ranges" ]
			.set_description( "Like -excl-range, but read the ranges from the specified file."
				"The file must contain a whitespace-separated list of genomic ranges to exclude from the analysis." )
			.set_takes_values_until_next_option() ;
		
		options.declare_group( "Output file options" ) ;
		options[ "-o" ]
			.set_description( "Path to output file.  Use \"-\" for stdout." )
			.set_takes_single_value()
			.set_default_value( "-" ) ;

		options.declare_group( "Model options" ) ;
		options[ "-incl-samples"]
			.set_description( "Filter out samples whose sample ID does not lie in the given file(s).")
			.set_takes_values( 1 )
			.set_minimum_multiplicity( 0 )
			.set_maximum_multiplicity( 100 ) ;
		options[ "-excl-samples"]
			.set_description( "Filter out samples whose sample ID lies in the given file.")
			.set_takes_values( 1 )
			.set_minimum_multiplicity( 0 )
			.set_maximum_multiplicity( 100 ) ;
		options[ "-incl-samples-where"]
			.set_description( "Include samples by specifying conditions on the values of columns in the sample file.")
			.set_takes_values( 1 )
			.set_minimum_multiplicity( 0 )
			.set_maximum_multiplicity( 100 ) ;
		options[ "-excl-samples-where"]
			.set_description( "Exclude samples by specifying conditions on the values of columns in the sample file.")
			.set_takes_values( 1 )
			.set_minimum_multiplicity( 0 )
			.set_maximum_multiplicity( 100 ) ;
		options[ "-minimum-allele-count" ]
			.set_description( "Skip predictors that have less than this minor allele count" )
			.set_takes_values(1)
			.set_default_value( 10 ) ;
		options[ "-covariates" ]
			.set_description( "Specify the name of one or more covariates to include in the model."
				" These must be columns named in the sample file." )
			.set_takes_values_until_next_option() ;
			
		options.declare_group( "Model fitting options" ) ;
		options[ "-tolerance" ]
			.set_description( "Tolerance to use when model fitting" )
			.set_takes_values(1)
			.set_default_value( 0.001 ) ;
		options[ "-max-iterations" ]
			.set_description( "Maximum iterations to allow when model fitting" )
			.set_takes_values(1)
			.set_default_value( 100 ) ;
		options[ "-max-causal-variants" ]
			.set_description( "Set the maximum number of variants allowed in a causal configuration")
			.set_takes_values(1)
			.set_default_value(5)
		;
		options[ "-additive" ]
			.set_description( "Specify that only additive effects are allowed for" ) ;
		;
		options.declare_group( "Miscellaneous options" ) ;
		options[ "-analysis-name" ]
			.set_description( "Specify a name to label results from this analysis with." )
			.set_takes_single_value()
			.set_default_value( "qctool analysis" ) ;
		options[ "-analysis-chunk" ]
			.set_description( "Specify a name denoting the current genomic region or chunk on which this is run.  This is intended for use in parallel environments." )
			.set_takes_single_value()
			.set_default_value( genfile::MissingValue() ) ;
		options.declare_group( "Miscellaneous options" ) ;
		options[ "-debug" ]
			.set_description( "Output debugging information." ) ;
		options [ "-log" ]
			.set_description( "Specify that " + globals::program_name + " should write a log file to the given file." )
			.set_takes_single_value() ;
	}
} ;

struct DosageStore {
public:
	typedef boost::function< void( std::size_t const, boost::optional< std::size_t > const ) > ProgressCallback ;
	typedef std::unique_ptr< DosageStore > UniquePtr ;

	static UniquePtr create() {
		return UniquePtr( new DosageStore() ) ;
	}
public:
	DosageStore() {}
	
	void load( genfile::SNPDataSource::UniquePtr source, ProgressCallback callback ) {
		load_unsafe( *source, callback ) ;
	}
	
	std::size_t number_of_samples() const { return m_ploidy[0].size() ; }
	std::size_t number_of_variants() const { return m_variants.size() ; }
	genfile::VariantIdentifyingData const& variant( std::size_t i ) const { return m_variants[i] ; }

	std::size_t estimate_memory_usage() const {
		std::size_t result = 0 ;
		for( std::size_t i = 0; i < m_variants.size(); ++i ) {
			result += m_variants[i].estimate_bytes_used() ;
			result += m_ploidy[i].size() ;
			result += m_AB[i].size() ;
			result += m_BB[i].size() ;
		}
		return result ;
	}
	
	std::string get_summary() const {
		using boost::format ;
		return (
			boost::format( "DosageStore: %d variants, %d samples, approx %.2fMb memory usage.\n" )
				% m_variants.size()
				% (m_variants.size() > 0 ? m_AB[0].size() : 0 )
				% (estimate_memory_usage() / 1000000.0)
		).str() ;
	}
	
	genfile::VariantIdentifyingData const get_variant( std::size_t i ) const {
		assert( i < m_variants.size() ) ;
		return m_variants[i] ;
	}
	
	template< typename Callback >
	void get_dosages( std::size_t i, Callback callback ) const {
		assert( i < m_variants.size() ) ;
		double const constant = double(0xFFFFFFFF >> 24) ;
		assert( i < m_variants.size() ) ;
		for( std::size_t j = 0; j < m_AB[i].size(); ++j ) {
			// unpack 8 bit bgen encoding
#if DEBUG_DOSAGESTORE
			if( j < 10 ) {
				std::cerr << "get_dosages(): " << j << ": " << int( m_AB[i][j] ) << ", " << int( m_BB[i][j] ) << ".\n" ;
			}
#endif
			callback( j, double( m_AB[i][j] ) / constant, double( m_BB[i][j] ) / constant ) ;
		}
	}
	
	std::vector< metro::SampleRange > const nonmissing_samples( std::size_t i ) const {
		assert( i < m_variants.size() ) ;
		return m_nonmissing_samples[i] ;
	}

private:

	/* Store genotype probabilities in 8 bit, BGEN-like encoding */
	struct DosageSetter {
		DosageSetter(
			std::vector< uint8_t >* ploidy,
			std::vector< uint8_t >* AB,
			std::vector< uint8_t >* BB
		):
			m_ploidy( ploidy ),
			m_AB( AB ),
			m_BB( BB ),
			m_bits(8),
			m_constant( double(0xFFFFFFFF >> (32 - m_bits))),
			m_sample_i(0),
			m_order_type( genfile::eUnknownOrderType )
		{}
		
		void initialise( std::size_t nSamples, std::size_t nAlleles ) {
			assert( nAlleles == 2 ) ;
			m_ploidy->resize( nSamples ) ;
			std::fill( m_ploidy->begin(), m_ploidy->end(), 0x80 ) ;
			m_AB->resize( nSamples ) ;
			std::fill( m_AB->begin(), m_AB->end(), 0 ) ;
			m_BB->resize( nSamples ) ;
			std::fill( m_BB->begin(), m_BB->end(), 0 ) ;
			m_last_nonmissing_sample_i = 0 ;
		}

		bool set_sample( std::size_t n ) {
			m_sample_i = n ;
			m_order_type = genfile::eUnknownOrderType ;
			return true ;
		}

		void set_number_of_entries(
			uint32_t ploidy, std::size_t n,
			genfile::OrderType const order_type,
			genfile::ValueType const value_type
		) {
			assert( ploidy <= 2 ) ;
			assert( (order_type == genfile::ePerOrderedHaplotype || genfile::ePerUnorderedGenotype) && value_type == genfile::eProbability ) ;
			(*m_ploidy)[m_sample_i] = ploidy ;
			m_order_type = order_type ;
		}

		void set_value( std::size_t entry_i, genfile::MissingValue const value ) {
			uint8_t& ploidy = (*m_ploidy)[m_sample_i] ;
			uint8_t& AB = (*m_AB)[m_sample_i] ;
			uint8_t& BB = (*m_BB)[m_sample_i] ;
			ploidy |= 0x80 ;
			AB = BB = 0 ;
			record_missing_sample( m_sample_i ) ;
		}

		void set_value( std::size_t entry_i, double const value ) {
			uint8_t& ploidy = (*m_ploidy)[m_sample_i] ;
			uint8_t& AB = (*m_AB)[m_sample_i] ;
			uint8_t& BB = (*m_BB)[m_sample_i] ;

#if DEBUG_DOSAGESTORE
			if( m_sample_i < 10 ) {
				std::cerr << "DosageSetter::set_value(): " << m_sample_i << ", " << entry_i << ": " << value << ".\n" ;
			}
#endif
			if( !(ploidy & 0x80) ) {
				if( entry_i == 1 ) {
					AB = value * m_constant ;
				} else if (entry_i == 2 ) {
					BB = value * m_constant ;
				}
			}
		}

		void set_value( std::size_t entry_i, genfile::Integer const value ) {
			assert(0) ; // expecting GT field
		}

		void finalise() {
			// add the final sample range if needed.
			record_missing_sample( m_ploidy->size() ) ;
		}
		
		std::vector< metro::SampleRange > const nonmissing_samples() { return m_nonmissing_samples ; }
		
		private:
			std::vector< uint8_t >* m_ploidy ;
			std::vector< uint8_t >* m_AB ;
			std::vector< uint8_t >* m_BB ;
			uint32_t m_bits ;
			double m_constant ;
			std::size_t m_sample_i ;
			std::size_t m_last_nonmissing_sample_i ;
			genfile::OrderType m_order_type ;
			std::vector< metro::SampleRange > m_nonmissing_samples ;
			
		void record_missing_sample( std::size_t sample_i ) {
			if( sample_i >= m_last_nonmissing_sample_i ) {
				m_nonmissing_samples.push_back(
					metro::SampleRange( m_last_nonmissing_sample_i, m_sample_i )
				) ;
			}
			m_last_nonmissing_sample_i = sample_i + 1 ;
		}
	} ;

	void load_unsafe( genfile::SNPDataSource& source, ProgressCallback callback ) {
		if( source.total_number_of_snps() ) {
			std::size_t N = *source.total_number_of_snps() ;
			m_variants.reserve( N ) ;
			m_ploidy.reserve( N ) ;
			m_AB.reserve( N ) ;
			m_BB.reserve( N ) ;
		}

		genfile::VariantIdentifyingData variant ;
		std::vector< uint16_t > data ;
		std::size_t count = 0 ;
		std::vector< uint8_t > ploidy, AB, BB ;
		
		while( source.get_snp_identifying_data( &variant )) {
			// ok, read dosages.
			std::cerr << "LOADING " << variant << ".\n" ;
			DosageSetter setter( &ploidy, &AB, &BB ) ;
			source.read_variant_data()->get( ":genotypes:", genfile::to_GP_unphased( setter ) ) ;
			m_variants.push_back( variant ) ;
			m_nonmissing_samples.push_back( setter.nonmissing_samples() ) ;
			m_ploidy.push_back( ploidy ) ;
			m_AB.push_back( AB ) ;
			m_BB.push_back( BB ) ;
			//m_data.push_back( data ) ;
			if( callback ) {
				callback( ++count, source.total_number_of_snps() ) ;
			}
		}
	}
	
	std::vector< genfile::VariantIdentifyingData > m_variants ;
	// To avoid using too much space, we encode dosage data as 16-bit integer
	// and expand to required format when requested.
	std::vector< std::vector< metro::SampleRange > > m_nonmissing_samples ;
	std::vector< std::vector< uint8_t > > m_ploidy ;
	std::vector< std::vector< uint8_t > > m_AB ;
	std::vector< std::vector< uint8_t > > m_BB ;
} ;

struct MFMApplication: public appcontext::ApplicationContext {
	MFMApplication( int argc, char** argv ):
		appcontext::ApplicationContext(
			globals::program_name,
			globals::program_version + ", revision " + globals::program_revision,
			std::auto_ptr< appcontext::OptionProcessor >( new MFMOptions ),
			argc,
			argv,
			"-log"
		)
	{
		process() ;
	}
	
private:
	
	void process() {
		try {
			unsafe_process() ;
		} catch( genfile::InputError const& e ) {
			ui().logger() << "!! Error (" << e.what() << "): " << e.format_message() << ".\n" ;
			throw appcontext::HaltProgramWithReturnCode( -1 ) ;
		}
		catch( genfile::FileNotFoundError const& e ) {
			ui().logger() << "\nError: No file matching \"" << e.filespec() << "\" could be found.\n" ;
			throw appcontext::HaltProgramWithReturnCode( -1 ) ;
		}
		catch( genfile::db::Error const& e ) {
			ui().logger() << "!! Error (" << e.what() << ") with the following statement: \""
				<< e.sql()
				<< "\".\n" ;
			throw appcontext::HaltProgramWithReturnCode( -1 ) ;
		}
	}
	
	void unsafe_process() {
		DosageStore::UniquePtr store = load_genotypes() ;

		genfile::CohortIndividualSource::UniquePtr
			samples = genfile::CohortIndividualSource::create( options().get< std::string >( "-s" ) ) ;

		metro::regression::LogLikelihood::UniquePtr
			ll = create_loglikelihood( samples->size() ) ;

		if( options().check( "-covariates" )) {
			add_covariates( ll->design(), *samples, options().get_values< std::string >( "-covariates" ) ) ;
		}
	
		set_outcome( *ll, *samples, options().get_value< std::string >( "-outcome" )) ;

		std::cerr << ll->design().get_summary() << "\n" ;

		run_search( *store, *ll ) ;
	}
	
	DosageStore::UniquePtr load_genotypes() {
		appcontext::UIContext::ProgressContext progress_context = ui().get_progress_context( "Loading data" ) ;
		DosageStore::UniquePtr store = DosageStore::create() ;
		store->load(
			open_snp_data_source( options().get< std::string >( "-g" ) ),
			progress_context
		) ;
		ui().logger() << store->get_summary() ;
		return store ;
	}
	
	genfile::SNPDataSource::UniquePtr
	open_snp_data_source( std::string const& filename ) const {
		genfile::Chromosome chromosome_hint ;
		std::string chromosome_indicator ;
		if( options().check_if_option_was_supplied( "-assume-chromosome" )) {
			chromosome_indicator = options().get_value< std::string >( "-assume-chromosome" ) ;
		}
		if( chromosome_indicator != "" ) {
			chromosome_hint = chromosome_indicator ;
		}

		genfile::SNPDataSource::UniquePtr source ;

		std::pair< std::string, std::string > uf = genfile::uniformise( filename ) ;

		{
			boost::optional< genfile::vcf::MetadataParser::Metadata > metadata ;
//			if( m_options.check( "-metadata" )) {
//				metadata = genfile::vcf::StrictMetadataParser(
//					m_options.get_value< std::string >( "-metadata" )
//				).get_metadata() ;
//			}
			source = genfile::SNPDataSource::create(
				filename,
				chromosome_hint,
				metadata,
				options().get< std::string >( "-filetype" )
			) ;
		}
		
		genfile::CommonSNPFilter::UniquePtr snp_filter = construct_snp_filter() ;
		// Filter SNPs if necessary
		if( snp_filter.get() ) {
			genfile::VariantIdentifyingDataFilteringSNPDataSource::UniquePtr snp_filtering_source
				= genfile::VariantIdentifyingDataFilteringSNPDataSource::create(
					source,
					genfile::VariantIdentifyingDataTest::UniquePtr( snp_filter.release() )
				) ;

			source.reset(
				snp_filtering_source.release()
			) ;
		}
		
		return source ;
	}

	genfile::CommonSNPFilter::UniquePtr construct_snp_filter() const {
		genfile::CommonSNPFilter::UniquePtr snp_filter ;

		if( options().check_if_option_was_supplied_in_group( "Input filtering options" )) {
			snp_filter.reset( new genfile::CommonSNPFilter ) ;
			if( options().check_if_option_was_supplied( "-incl-range" )) {
				std::vector< std::string > specs = options().get_values< std::string >( "-incl-range" ) ;
				for ( std::size_t i = 0; i < specs.size(); ++i ) {
					snp_filter->include_snps_in_range(
						genfile::GenomePositionRange::parse( specs[i] )
					) ;
				}
			}

			if( options().check_if_option_was_supplied( "-excl-range" )) {
				std::vector< std::string > specs = options().get_values< std::string >( "-excl-range" ) ;
				for ( std::size_t i = 0; i < specs.size(); ++i ) {
					snp_filter->exclude_snps_in_range(
						genfile::GenomePositionRange::parse( specs[i] )
					) ;
				}
			}

			if( options().check_if_option_was_supplied( "-incl-ranges" )) {
				std::vector< std::string > files = options().get_values< std::string >( "-incl-ranges" ) ;
				for( std::string const& filename: files ) {
					std::auto_ptr< std::istream > in = genfile::open_text_file_for_input( filename ) ;
					std::string range ;
					while( (*in) >> range ) {
						snp_filter->include_snps_in_range(
							genfile::GenomePositionRange::parse( range )
						) ;
					}
				}
			}

			if( options().check_if_option_was_supplied( "-excl-ranges" )) {
				std::vector< std::string > files = options().get_values< std::string >( "-excl-ranges" ) ;
				for( std::string const& filename: files ) {
					std::auto_ptr< std::istream > in = genfile::open_text_file_for_input( filename ) ;
					std::string range ;
					while( (*in) >> range ) {
						snp_filter->exclude_snps_in_range(
							genfile::GenomePositionRange::parse( range )
						) ;
					}
				}
			}
		}
		return snp_filter ;
	}
	
	metro::regression::LogLikelihood::UniquePtr create_loglikelihood( std::size_t number_of_samples ) {
		typedef std::vector< std::string > Names ;
		typedef std::vector< metro::SampleRange > SampleRanges ;
		using namespace metro::regression ;

		Eigen::MatrixXd outcome = Eigen::MatrixXd::Zero( number_of_samples, 2 ) ;

		Design::UniquePtr design = Design::create(
			outcome, SampleRanges(), Names({ "outcome=0", "outcome=1"} ),
			Names({
				"add1", "het1",
				"add2", "het2",
				"add3", "het3",
				"add4", "het4",
				"add5", "het5"
			})
		) ;
		LogLikelihood::UniquePtr ll( metro::regression::Logistic::create( design ).release() ) ;
		return ll ;
	}
	
	void add_covariates(
		metro::regression::Design& design,
		genfile::CohortIndividualSource const& samples,
		std::vector< std::string > const& covariates
	) {
		ui().logger() << "Adding covariates...\n" ;
		{
			std::set< std::string > uniqueCovariates( covariates.begin(), covariates.end() ) ;
			if( uniqueCovariates.size() != covariates.size() ) {
				throw genfile::BadArgumentError(
					"add_covariates()",
					"covariates=\"" + genfile::string_utils::join( covariates, " " ) + "\"",
					"Covariates should not be duplicated."
				) ;
			}
		}
		genfile::CohortIndividualSource::ColumnSpec const& spec = samples.get_column_spec() ;
		for( std::size_t i = 0; i < covariates.size(); ++i ) {
			std::string const& covariateName = covariates[i] ;
			std::size_t const column_index = spec.find_column( covariateName ) ;
			genfile::CohortIndividualSource::SingleColumnSpec columnSpec = spec[ column_index ] ;
			genfile::CrossCohortCovariateValueMapping::UniquePtr mapping
				= genfile::CrossCohortCovariateValueMapping::create( columnSpec, true ) ;
			mapping->add_source( samples ) ;
			if( columnSpec.is_discrete() ) {
				design.add_discrete_covariate(
					covariateName,
					[&samples, &column_index, &mapping] ( std::size_t sample_index ) {
						int value = -1 ;
						genfile::VariantEntry entry = samples.get_entry( sample_index, column_index ) ;
						if( !entry.is_missing() ) {
							value = mapping->get_mapped_value( entry ).as< int >() ;
						}
						return value ;
					},
					[&mapping]( int level ) {
						genfile::VariantEntry entry = mapping->get_unmapped_value( level ) ;
						return entry.as< std::string >() ;
					},
					mapping->get_number_of_distinct_mapped_values()
				) ;
			} else {
				design.add_single_covariate(
					covariateName,
					[&samples, &column_index, &mapping]( std::size_t sample_index ) {
						double value = metro::NA ;
						genfile::VariantEntry entry = samples.get_entry( sample_index, column_index ) ;
						if( !entry.is_missing() ) {
							value = mapping->get_mapped_value( entry ).as< double >() ;
						}
						return value ;
					}
				) ;
			}
			
			ui().logger()
				<< "++ Added covariate: \"" + covariateName + "\":\n"
				<<  mapping->get_summary( "     " )
				<< "\n\n" ;
		}
	}

	void set_outcome(
		metro::regression::LogLikelihood& ll,
		genfile::CohortIndividualSource const& samples,
		std::string const& column
	) const {
		typedef std::vector< std::string > Names ;
		typedef std::vector< metro::SampleRange > SampleRanges ;
		Eigen::MatrixXd outcome = Eigen::MatrixXd::Zero( samples.size(), 2 ) ;
		SampleRanges nonmissingness ;
		get_binary_outcome( samples, column, &outcome, &nonmissingness ) ;
		ll.design().set_outcome(
			outcome, nonmissingness,
			Names({ column + "=0", column + "=1" })
		) ;
	}

	void get_binary_outcome(
		genfile::CohortIndividualSource const& samples,
		std::string const& column,
		Eigen::MatrixXd* outcome,
		std::vector< metro::SampleRange >* nonmissingness
	) const {
		std::size_t column_i = samples.get_column_spec().find_column( column ) ;
		assert( samples.get_column_spec()[ column_i ].is_discrete() ) ;
		std::size_t last_nonmissing_sample_i = 0 ;
		outcome->setZero( samples.size(), 2 ) ;
		for( std::size_t i = 0; i < samples.size(); ++i ) {
			genfile::VariantEntry const& entry = samples.get_entry( i, column_i ) ;
			if( entry.is_missing() ) {
				nonmissingness->push_back( metro::SampleRange( last_nonmissing_sample_i, i )) ;
				last_nonmissing_sample_i = i+1 ;
			} else {
				int value = entry.as< int >() ;
				assert( value == 0 || value == 1 ) ;
				(*outcome)(i,value) = 1 ;
			}
		}
		if( last_nonmissing_sample_i < samples.size() ) {
			nonmissingness->push_back( metro::SampleRange( last_nonmissing_sample_i, samples.size() )) ;
		}
#if DEBUG
		std::cerr << "get_outcome(): outcome is:\n"
			<< outcome->block(0,0,10,2 ) << "\n"
			<< "nonmissingness: " << *nonmissingness << "\n" ;
#endif
	}


	typedef std::map< std::vector< metro::SampleRange >, std::pair< Eigen::VectorXd, double > > NullLLStore ;

	double test_variant(
		metro::ShotgunStochasticSearch::SelectedStates const& pick,
		DosageStore const& store,
		metro::regression::LogLikelihood& ll,
		NullLLStore& null_ll_store
	) {
#if DEBUG
		std::cerr << "   TESTING: " << print_state( store.number_of_variants(), pick ) << ".\n" ;
#endif
		using namespace metro::regression ;
		using metro::SampleRange ;
		
		double const minus_infinity = -std::numeric_limits< double >::infinity() ;
		double const log_weight = ( (pick.size() == 0) || (pick.size() > 5) )
			? minus_infinity
			: (pick.size() * std::log( 1.0 / store.number_of_variants() )) ;
	
		if( log_weight == minus_infinity ) {
			// Disallowed state, don't bother fitting.
			return minus_infinity ;
		}

		boost::format parameter_format( "%s%d/%s" ) ;
		bool const debug = options().check( "-debug" ) ;

		assert( pick.size() < 6 ) ;
		Eigen::MatrixXd predictors = Eigen::MatrixXd::Zero( store.number_of_samples(), 10 ) ;
		std::vector< metro::SampleRange > nonmissing_samples( 1, metro::SampleRange( 0, store.number_of_samples() )) ;

		metro::IndependentParameterDistribution prior( ll.get_parameter_names() ) ;
		metro::IndependentParameterDistribution null_prior( ll.get_parameter_names() ) ;

		double const add_prior_obs = 32.0 ;
		double const het_prior_obs = options().check( "-additive" ) ? 1000.0 : 32.0 ;

		for( std::size_t i = 0; i < 5; ++i ) {
			null_prior.set_prior(
				(parameter_format % "add" % (i+1) % ll.design().get_outcome_name(1) ).str(),
				metro::distributions::LogF::create( 10000.0, 10000.0 )
			) ;
			null_prior.set_prior(
				(parameter_format % "het" % (i+1) % ll.design().get_outcome_name(1) ).str(),
				metro::distributions::LogF::create( 10000.0, 10000.0 )
			) ;
		}
		
		for( std::size_t i = 0; i < pick.size(); ++i ) {
			store.get_dosages(
				pick[i],
				[&predictors,i] ( int sample, double ab, double bb ){
					predictors( sample, i*2+0) = ab + 2*bb ;
					predictors( sample, i*2+1) = ab ;
				}
			) ;
			nonmissing_samples = metro::impl::intersect_ranges(
				nonmissing_samples,
				store.nonmissing_samples(pick[i])
			) ;
			prior.set_prior(
				(parameter_format % "add" % (i+1) % ll.design().get_outcome_name(1) ).str(),
				metro::distributions::LogF::create( add_prior_obs, add_prior_obs )
			) ;
			prior.set_prior(
				(parameter_format % "het" % (i+1) % ll.design().get_outcome_name(1) ).str(),
				metro::distributions::LogF::create( het_prior_obs, het_prior_obs )
			) ;
		}
		for( std::size_t i = pick.size(); i < 5; ++i ) {
			prior.set_prior(
				(parameter_format % "add" % (i+1) % ll.design().get_outcome_name(1) ).str(),
				metro::distributions::LogF::create( add_prior_obs, add_prior_obs )
			) ;
			prior.set_prior(
				(parameter_format % "het" % (i+1) % ll.design().get_outcome_name(1) ).str(),
				metro::distributions::LogF::create( het_prior_obs, het_prior_obs )
			) ;
		}

		// Set up a trace for model fitting iterations.
		CholeskyStepper::Tracer tracer ;
		if( debug ) {
			tracer = [this] ( 
				int iteration,
				double ll,
				double target_ll,
				CholeskyStepper::Vector const& point,
				CholeskyStepper::Vector const& first_derivative,
				CholeskyStepper::Vector const& step,
				bool converged
			) {
				this->ui().logger()
					<< " ITERATION: " << iteration << "\n"
					<< "        LL: " << ll << "\n"
					<< "    TARGET: " << target_ll << "\n"
					<< "     POINT: " << point.transpose() << "\n"
					<< "DERIVATIVE: " << first_derivative.transpose() << "\n"
					<< "      STEP: " << step.transpose() << "\n"
					<< " CONVERGED: " << ( converged ? "yes" : "no" ) << "\n" ;
			} ;
		}

		// To compute the BF we need the null model.
		// The null model does not depend on the SNPs, but might depend on the missing samples.
		// We cache the value for speed if the nonmissing samples don't change.
		std::vector< std::string > comments ;
		// null_ll will be log-marginal likelihood of null model
		// i.e. logarithm of prior x likelihood, integrated over parameters.
		double null_ll = 0.0 ;
		Eigen::VectorXd null_parameters ;
		{
			NullLLStore::const_iterator where = null_ll_store.find( nonmissing_samples ) ;
			if( where == null_ll_store.end() ) {
				if( debug ) {
					this->ui().logger() << "---> fitting NULL...\n" ;
				}
				ll.design().set_predictors( Eigen::MatrixXd::Zero( store.number_of_samples(), 10 ), nonmissing_samples ) ;
				LogUnnormalisedPosterior posterior( ll, null_prior ) ;
				metro::regression::CholeskyStepper stopping_condition( 0.01, 100, tracer ) ;
				std::pair< bool, int > fit = metro::regression::fit_model(
					posterior,
					"null",
					Eigen::VectorXd::Zero( ll.identify_parameters().rows() ),
					stopping_condition,
					&comments
				) ;
					
				null_ll = laplace_approximate( posterior ) ;
				null_parameters = posterior.parameters() ;
				//null_ll = posterior.get_value_of_function() ;
				where = null_ll_store.insert(
					NullLLStore::value_type(
						nonmissing_samples,
						NullLLStore::mapped_type(
							ll.parameters(),
							null_ll
						)
					)
				).first ;
			} else {
				null_parameters = where->second.first ;
				null_ll = where->second.second ;
			}
		}

		ll.design().set_predictors( predictors, nonmissing_samples ) ;
		LogUnnormalisedPosterior posterior( ll, prior ) ;

		double posterior_weight = minus_infinity ;
		double result = minus_infinity ;

		if( log_weight > minus_infinity ) {
			if( debug ) {
				this->ui().logger() << "---> fitting full...\n" ;
			}
			metro::regression::CholeskyStepper stopping_condition( 0.01, 100, tracer ) ;
			std::pair< bool, int > fit = metro::regression::fit_model(
				posterior,
				"full",
				null_parameters,
				stopping_condition,
				&comments
			) ;
			if( fit.first ) {
				result = laplace_approximate( posterior ) - null_ll + log_weight ;
				//result = posterior.get_value_of_function() - null_ll + log_weight ;
			}

#if DEBUG
			std::cerr << print_state( store.number_of_variants(), pick ) << ".\n" ;
			//std::cerr << nonmissing_samples << ".\n" ;
			// std::cerr << "PREDICTORS:\n" << predictors.block( 0, 0, 10, predictors.cols() ) << ".\n" ;
			std::cerr << posterior.get_summary() << "\n" ;
			std::cerr << "  INCLUDED: " << posterior.ll().design().nonmissing_samples() << "\n" ;
			std::cerr << " CONVERGED: " << (fit.first ? "1" : "0") << "\n" ;
			std::cerr << "        LL: " << posterior.get_value_of_function() << "\n" ;
			std::cerr << "      NULL: " << null_ll << "\n" ;
			std::cerr << " pick.size: " << pick.size() << "\n" ;
			std::cerr << "LOG WEIGHT: " << log_weight << "\n" ;
			std::cerr << "    RESULT: " << result << "\n" ;
		
			std::cerr << "\n+++++++++++++++++++++++++\n" ;
#endif		
		}
		
		return result ;
	}
	
	// Compute laplace approximation.
	// It is assumed that the function has already been maximised.
	double laplace_approximate( metro::SmoothFunction const& function ) const {
		double const fx = function.get_value_of_function() ;
		metro::SmoothFunction::Matrix const& H = function.get_value_of_second_derivative() ;
		double const log_2pi = std::log( 2.0 * 3.1415926535897932384626 ) ;
		Eigen::ColPivHouseholderQR< metro::SmoothFunction::Matrix > solver( -H ) ;
		return
			fx + 0.5 * ( function.number_of_parameters() * log_2pi - solver.logAbsDeterminant() ) ;
	}

	void run_search( DosageStore& store, metro::regression::LogLikelihood& ll ) {
		// Do a test search for now
		NullLLStore null_ll_store ;

		ui().logger() << "Running shotgun stochastic search...\n" ;

		metro::ShotgunStochasticSearch ss(
			store.number_of_variants(),
			[this, &store, &ll, &null_ll_store]( metro::ShotgunStochasticSearch::SelectedStates const& s ) {
				return this->test_variant( s, store, ll, null_ll_store ) ;
			},
			static_cast<std::uint32_t>(std::time(0))
		) ;

		for( std::size_t i = 0; i < 100; ++i ) {
			boost::timer::cpu_timer timer ;
			metro::ShotgunStochasticSearch::SelectedStates const& pick = ss.update() ;
			
			ui().logger() << "Iteration " << i << ": "
				<< "took " << boost::timer::format( timer.elapsed(), 2, "%ts" )
				<< ", state is: " << print_state( store.number_of_variants(), pick )
				<< "\n" ;
		}

		ui().logger() << "Outputting search results...\n" ;
		output_search_results( ss, store ) ;

		ui().logger() << "Fine-mapping complete.\n" ;
	}
	
	void output_search_results(
		metro::ShotgunStochasticSearch const& ss,
		DosageStore const& store
	) {
		qcdb::MultiVariantStorage::UniquePtr outputter
			= qcdb::MultiVariantStorage::create(
				options().get< std::string >( "-o" ),
				5,
				options().get< std::string >( "-analysis-name" ),
				options().get< std::string >( "-analysis-chunk" ),
				options().get_values_as_map()
		) ;
		outputter->add_variable( "loglikelihood" ) ;
		outputter->add_variable( "logposterior" ) ;
		outputter->add_variable( "posterior" ) ;

		std::vector< genfile::VariantIdentifyingData > variants ;

		auto comparator = []( double a, double b ) { return a > b ; } ;
		typedef std::multimap< double, metro::ShotgunStochasticSearch::SelectedStates, decltype(comparator) > OrderedStates ;
		OrderedStates ordered_states( comparator ) ;
		std::vector< double > posterior_weights ;
		ss.visited_states(
			[&ordered_states, &posterior_weights](
				metro::ShotgunStochasticSearch::SelectedStates const& states,
				double value
			) {
				std::cerr << "GOT: " << states.size() << ", " << value << "\n" ;
				ordered_states.insert( std::make_pair( value, states )) ;
				posterior_weights.push_back( value ) ;
			}
		) ;

		double const total_log_weight = metro::log_sum_exp( posterior_weights ) ;
		std::cerr << "TOTAL LOG WEIGHT:" << total_log_weight << "\n" ;
		int count = 0 ;
		for( OrderedStates::const_iterator i = ordered_states.begin(); i != ordered_states.end(); ++i, ++count ) {
			metro::ShotgunStochasticSearch::SelectedStates const& states = i->second ;
			variants.resize( states.size() ) ;
			for( std::size_t i = 0; i < states.size(); ++i ) {
				variants[i] = store.variant( states[i] ) ;
			}
			outputter->store_data_for_key(
				variants,
				"rank",
				count
			) ;
			outputter->store_data_for_key(
				variants,
				"loglikelihood",
				i->first
			) ;
			outputter->store_data_for_key(
				variants,
				"logposterior",
				i->first - total_log_weight
			) ;
			outputter->store_data_for_key(
				variants,
				"logposterior",
				std::exp( i->first - total_log_weight )
			) ;
		}
		outputter->finalise() ;
	}

#if 0
	void create_query( genfile::bgen::Query* query ) {
		if( options().check( "-incl-range" )) {
			auto const elts = options().get_values< std::string >( "-incl-range" ) ;
			for( std::string const& elt: elts ) {
				query->include_range( parse_range( elt )) ;
			}
		}
		if( options().check( "-excl-range" )) {
			auto const elts = options().get_values< std::string >( "-excl-range" ) ;
			for( std::string const& elt: elts ) {
				query->exclude_range( parse_range( elt )) ;
			}
		}
		if( options().check( "-incl-rsids" )) {
			auto const ids = options().get_values< std::string >( "-incl-rsids" ) ;
			query->include_rsids( ids ) ;
		}

		if( options().check( "-excl-rsids" )) {
			auto const ids = options().get_values< std::string >( "-excl-rsids" ) ;
			query->exclude_rsids( ids ) ;
		}
	}
	
	genfile::bgen::IndexQuery::GenomicRange parse_range( std::string const& spec ) const {
		std::size_t colon_pos = spec.find( ':' ) ;
		if ( colon_pos == std::string::npos ) {
			throw std::invalid_argument( "spec=\"" + spec + "\"" ) ;
		}

		std::vector< std::string > pieces ;
		pieces.push_back( spec.substr( 0, colon_pos )) ;
		pieces.push_back( spec.substr( colon_pos+1, spec.size() )) ;

		if( pieces.size() != 2 ) {
			throw std::invalid_argument( "spec=\"" + spec + "\"" ) ;
		}

		std::size_t separator_pos = pieces[1].find( '-' ) ;
		if ( separator_pos == std::string::npos ) {
			throw std::invalid_argument( "spec=\"" + spec + "\"" ) ;
		}

		std::string chromosome( pieces[0] ) ;
		int pos1 = (separator_pos == 0) ? 0 : std::stoi( pieces[1].substr( 0, separator_pos ) ) ;
		int pos2 = (separator_pos == (pieces[1].size()-1)) ? std::numeric_limits< int >::max() : std::stoi( pieces[1].substr( separator_pos + 1, pieces[1].size() ) ) ;
		assert( pos1 >= 0 ) ;
		assert( pos2 >= pos1 ) ;

		return genfile::bgen::IndexQuery::GenomicRange( chromosome, pos1, pos2 ) ;
	}
#endif
} ;

int main( int argc, char** argv ) {
	try {
		MFMApplication app( argc, argv ) ;
	}
	catch( appcontext::HaltProgramWithReturnCode const& e ) {
		return e.return_code() ;
	}
	return 0 ;
}

